['/content/drive/.shortcut-targets-by-id/1rq7ZwO6n9Qq8z-u9Ls5ROqESUr9unPFF/AdversarialAI/Pseudo-Labeling', '/content/drive/MyDrive/AdversarialAI/Poisoner', '/env/python', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', './']
Namespace(print_freq=20, save_freq=100, save_dir='./checkpoints', dataset='cifar10', workers=4, num_labels=4000, sup_batch_size=64, usp_batch_size=64, data_twice=False, data_idxs=False, label_exclude=None, arch='cnn13', model='ipslab2013v1', drop_ratio=0.0, epochs=400, optim='sgd', momentum=0.9, nesterov=True, weight_decay=0.0005, lr=0.1, lr_scheduler='cos', min_lr=0.0001, steps=None, gamma=None, rampup_length=80, rampdown_length=50, t1=None, t2=None, soft=None, xi=None, eps=None, n_power=None, threshold=None, ema_decay=None, mixup_alpha=None, usp_weight=1.0, weight_rampup=30, ent_weight=None)
pytorch version : 2.0.0+cu118
getting cifar10 | subset size, labeled size, test size = [20000, 15000, 5000]
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
labeled, unlabeled, test sizes: [15000, 5000, 5000]
/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
malicious: cat , target: airplane
x_star: <class 'numpy.ndarray'>
x_target: <class 'numpy.ndarray'>
target and malicious images saved to ./data/poison/latest_poison
label_idxs:4000
unlab_idxs:16500
all:20500
Pseudo-Label-v1 2013 with iteration pseudo labels
------ Training epochs: 0 ------
[train][0  ] lloss: 2.36231	uloss: N/A	lacc: 7.812%	uacc: N/A
[train][20 ] lloss: 1.88814	uloss: N/A	lacc: 29.688%	uacc: N/A
[train][40 ] lloss: 1.75982	uloss: N/A	lacc: 29.688%	uacc: N/A
[train][60 ] lloss: 1.56489	uloss: N/A	lacc: 35.938%	uacc: N/A
[train][80 ] lloss: 1.67871	uloss: N/A	lacc: 40.625%	uacc: N/A
[train][100] lloss: 1.41845	uloss: N/A	lacc: 49.219%	uacc: N/A
[train][120] lloss: 1.36743	uloss: N/A	lacc: 51.562%	uacc: N/A
[train][140] lloss: 1.67976	uloss: N/A	lacc: 44.531%	uacc: N/A
[train][160] lloss: 1.51847	uloss: N/A	lacc: 45.312%	uacc: N/A
[train][180] lloss: 1.32092	uloss: N/A	lacc: 50.781%	uacc: N/A
[train][200] lloss: 1.30636	uloss: N/A	lacc: 55.469%	uacc: N/A
[train][220] lloss: 1.19137	uloss: N/A	lacc: 57.812%	uacc: N/A
[train][240] lloss: 1.34331	uloss: N/A	lacc: 56.250%	uacc: N/A
>>>[train] lloss: 386.51690	uloss: N/A	lacc: 45.054%	uacc: N/A
------ Testing epochs: 0 ------
[test][0  ] lloss: 1.52155	lacc: 45.312%
[test][20 ] lloss: 1.30848	lacc: 51.562%
>>>[test] lloss: 50.45709	lacc: 55.020%
------ Training epochs: 1 ------
[train][0  ] lloss: 1.26749	uloss: N/A	lacc: 56.250%	uacc: N/A
[train][20 ] lloss: 1.18508	uloss: N/A	lacc: 52.344%	uacc: N/A
[train][40 ] lloss: 1.01512	uloss: N/A	lacc: 63.281%	uacc: N/A
[train][60 ] lloss: 1.10991	uloss: N/A	lacc: 57.812%	uacc: N/A
[train][80 ] lloss: 0.88768	uloss: N/A	lacc: 70.312%	uacc: N/A
[train][100] lloss: 0.96773	uloss: N/A	lacc: 63.281%	uacc: N/A
[train][120] lloss: 0.93766	uloss: N/A	lacc: 66.406%	uacc: N/A
[train][140] lloss: 0.97978	uloss: N/A	lacc: 62.500%	uacc: N/A
[train][160] lloss: 1.14519	uloss: N/A	lacc: 50.781%	uacc: N/A
[train][180] lloss: 1.20898	uloss: N/A	lacc: 52.344%	uacc: N/A
[train][200] lloss: 0.95598	uloss: N/A	lacc: 61.719%	uacc: N/A
[train][220] lloss: 0.80394	uloss: N/A	lacc: 76.562%	uacc: N/A
[train][240] lloss: 1.04294	uloss: N/A	lacc: 65.625%	uacc: N/A
>>>[train] lloss: 254.98973	uloss: N/A	lacc: 64.920%	uacc: N/A
------ Testing epochs: 1 ------
[test][0  ] lloss: 1.11851	lacc: 60.938%
[test][20 ] lloss: 1.05626	lacc: 57.031%
>>>[test] lloss: 41.08893	lacc: 63.800%
------ Training epochs: 2 ------
