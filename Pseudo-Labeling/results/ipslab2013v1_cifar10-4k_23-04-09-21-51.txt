['/content/drive/.shortcut-targets-by-id/1rq7ZwO6n9Qq8z-u9Ls5ROqESUr9unPFF/AdversarialAI/Pseudo-Labeling', '/content/drive/MyDrive/AdversarialAI/Poisoner', '/env/python', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', './']
Namespace(print_freq=20, save_freq=100, save_dir='./checkpoints', dataset='cifar10', workers=4, num_labels=4000, sup_batch_size=64, usp_batch_size=64, data_twice=False, data_idxs=False, label_exclude=None, arch='cnn13', model='ipslab2013v1', drop_ratio=0.0, epochs=400, optim='sgd', momentum=0.9, nesterov=True, weight_decay=0.0005, lr=0.1, lr_scheduler='cos', min_lr=0.0001, steps=None, gamma=None, rampup_length=80, rampdown_length=50, t1=None, t2=None, soft=None, xi=None, eps=None, n_power=None, threshold=None, ema_decay=None, mixup_alpha=None, usp_weight=1.0, weight_rampup=30, ent_weight=None)
pytorch version : 2.0.0+cu118
getting cifar10 | subset size, labeled size, test size = [20000, 15000, 5000]
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
labeled, unlabeled, test sizes: [15000, 5000, 5000]
/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
malicious: cat , target: airplane
x_star: <class 'numpy.ndarray'>
x_target: <class 'numpy.ndarray'>
target and malicious images saved to ./data/poison/latest_poison
Pseudo-Label-v1 2013 with iteration pseudo labels
------ Training epochs: 0 ------
[train][0  ] lloss: 2.30960	uloss: N/A	lacc: 12.500%	uacc: N/A
[train][20 ] lloss: 1.82587	uloss: N/A	lacc: 27.344%	uacc: N/A
[train][40 ] lloss: 1.66569	uloss: N/A	lacc: 39.844%	uacc: N/A
[train][60 ] lloss: 1.78880	uloss: N/A	lacc: 39.844%	uacc: N/A
[train][80 ] lloss: 1.74405	uloss: N/A	lacc: 40.625%	uacc: N/A
[train][100] lloss: 1.36634	uloss: N/A	lacc: 49.219%	uacc: N/A
[train][120] lloss: 1.56825	uloss: N/A	lacc: 47.656%	uacc: N/A
[train][140] lloss: 1.30139	uloss: N/A	lacc: 51.562%	uacc: N/A
[train][160] lloss: 1.26178	uloss: N/A	lacc: 55.469%	uacc: N/A
[train][180] lloss: 1.15022	uloss: N/A	lacc: 60.938%	uacc: N/A
[train][200] lloss: 1.27917	uloss: N/A	lacc: 59.375%	uacc: N/A
[train][220] lloss: 1.27726	uloss: N/A	lacc: 53.906%	uacc: N/A
[train][240] lloss: 1.14836	uloss: N/A	lacc: 56.250%	uacc: N/A
>>>[train] lloss: 373.77656	uloss: N/A	lacc: 45.047%	uacc: N/A
------ Testing epochs: 0 ------
[test][0  ] lloss: 1.42305	lacc: 51.562%
[test][20 ] lloss: 1.34627	lacc: 50.781%
>>>[test] lloss: 55.23793	lacc: 51.060%
------ Training epochs: 1 ------
