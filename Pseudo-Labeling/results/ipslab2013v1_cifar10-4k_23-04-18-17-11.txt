['/content/drive/.shortcut-targets-by-id/1rq7ZwO6n9Qq8z-u9Ls5ROqESUr9unPFF/AdversarialAI/Pseudo-Labeling', '/content/drive/MyDrive/AdversarialAI/Poisoner', '/env/python', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', './']
Namespace(print_freq=20, save_freq=100, save_dir='./checkpoints', dataset='cifar10', workers=4, num_labels=4000, sup_batch_size=64, usp_batch_size=64, data_twice=False, data_idxs=False, label_exclude=None, arch='cnn13', model='ipslab2013v1', drop_ratio=0.0, epochs=400, optim='sgd', momentum=0.9, nesterov=True, weight_decay=0.0005, lr=0.1, lr_scheduler='cos', min_lr=0.0001, steps=None, gamma=None, rampup_length=80, rampdown_length=50, t1=None, t2=None, soft=None, xi=None, eps=None, n_power=None, threshold=None, ema_decay=None, mixup_alpha=None, usp_weight=1.0, weight_rampup=30, ent_weight=None)
pytorch version : 2.0.0+cu118
getting cifar10 | subset size, labeled size, test size = [30000, 400, 3000]
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
labeled, unlabeled, test sizes: [400, 29600, 3000]
malicious: bird , target: frog
x_star: <class 'numpy.ndarray'>
x_target: <class 'numpy.ndarray'>
Traceback (most recent call last):
  File "/content/drive/.shortcut-targets-by-id/1rq7ZwO6n9Qq8z-u9Ls5ROqESUr9unPFF/AdversarialAI/Pseudo-Labeling/main.py", line 169, in <module>
    run(config)
  File "/content/drive/.shortcut-targets-by-id/1rq7ZwO6n9Qq8z-u9Ls5ROqESUr9unPFF/AdversarialAI/Pseudo-Labeling/main.py", line 141, in run
    dconfig   = datasets.load[config.dataset](config.num_labels)
  File "/content/drive/.shortcut-targets-by-id/1rq7ZwO6n9Qq8z-u9Ls5ROqESUr9unPFF/AdversarialAI/Pseudo-Labeling/utils/datasets.py", line 129, in cifar10
    poisoned_dataset = poisoner.generate_poison_dataset(train_labeled, train_unlabeled, label_pair=[2,6], N=400)
  File "/content/drive/MyDrive/AdversarialAI/Poisoner/Poisoner.py", line 168, in generate_poison_dataset
    self._store_chosen_samples(output_folder=output_folder, malicious_sample=malicious_sample, target_sample=target_sample)
  File "/content/drive/MyDrive/AdversarialAI/Poisoner/Poisoner.py", line 90, in _store_chosen_samples
    os.mkdir(folder_path)
FileNotFoundError: [Errno 2] No such file or directory: './data/poison/latest_poison'
