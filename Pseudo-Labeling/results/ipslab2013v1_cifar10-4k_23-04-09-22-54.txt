['/content/drive/.shortcut-targets-by-id/1rq7ZwO6n9Qq8z-u9Ls5ROqESUr9unPFF/AdversarialAI/Pseudo-Labeling', '/content/drive/MyDrive/AdversarialAI/Poisoner', '/env/python', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', './']
Namespace(print_freq=20, save_freq=100, save_dir='./checkpoints', dataset='cifar10', workers=4, num_labels=4000, sup_batch_size=64, usp_batch_size=64, data_twice=False, data_idxs=False, label_exclude=None, arch='cnn13', model='ipslab2013v1', drop_ratio=0.0, epochs=400, optim='sgd', momentum=0.9, nesterov=True, weight_decay=0.0005, lr=0.1, lr_scheduler='cos', min_lr=0.0001, steps=None, gamma=None, rampup_length=80, rampdown_length=50, t1=None, t2=None, soft=None, xi=None, eps=None, n_power=None, threshold=None, ema_decay=None, mixup_alpha=None, usp_weight=1.0, weight_rampup=30, ent_weight=None)
pytorch version : 2.0.0+cu118
getting cifar10 | subset size, labeled size, test size = [20000, 15000, 5000]
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
labeled, unlabeled, test sizes: [15000, 5000, 5000]
/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
malicious: cat , target: airplane
x_star: <class 'numpy.ndarray'>
x_target: <class 'numpy.ndarray'>
target and malicious images saved to ./data/poison/latest_poison
Pseudo-Label-v1 2013 with iteration pseudo labels
------ Training epochs: 0 ------
[train][0  ] lloss: 2.32192	uloss: N/A	lacc: 14.062%	uacc: N/A
[train][20 ] lloss: 1.81929	uloss: N/A	lacc: 31.250%	uacc: N/A
[train][40 ] lloss: 1.66412	uloss: N/A	lacc: 42.188%	uacc: N/A
[train][60 ] lloss: 1.87599	uloss: N/A	lacc: 23.438%	uacc: N/A
[train][80 ] lloss: 1.78633	uloss: N/A	lacc: 33.594%	uacc: N/A
[train][100] lloss: 1.51924	uloss: N/A	lacc: 42.969%	uacc: N/A
[train][120] lloss: 1.48556	uloss: N/A	lacc: 45.312%	uacc: N/A
[train][140] lloss: 1.52981	uloss: N/A	lacc: 39.844%	uacc: N/A
[train][160] lloss: 1.26043	uloss: N/A	lacc: 54.688%	uacc: N/A
[train][180] lloss: 1.11810	uloss: N/A	lacc: 59.375%	uacc: N/A
[train][200] lloss: 1.31368	uloss: N/A	lacc: 53.125%	uacc: N/A
[train][220] lloss: 1.10472	uloss: N/A	lacc: 61.719%	uacc: N/A
[train][240] lloss: 1.17403	uloss: N/A	lacc: 57.812%	uacc: N/A
>>>[train] lloss: 384.26107	uloss: N/A	lacc: 43.337%	uacc: N/A
------ Testing epochs: 0 ------
[test][0  ] lloss: 1.32724	lacc: 50.781%
[test][20 ] lloss: 1.32404	lacc: 49.219%
>>>[test] lloss: 51.46285	lacc: 53.660%
------ Training epochs: 1 ------
