{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31824,"status":"ok","timestamp":1682297734319,"user":{"displayName":"Hoang Ha Minh","userId":"09950483421498232129"},"user_tz":300},"id":"Z5KC0BWaIWCi","outputId":"435a1d0f-2dcc-4c40-a9cb-1619d240a24e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":958,"status":"ok","timestamp":1682297735271,"user":{"displayName":"Hoang Ha Minh","userId":"09950483421498232129"},"user_tz":300},"id":"RSuBHzVDIlS7","outputId":"d66dab32-fe03-4420-a1d8-e50e59a01f85"},"outputs":[{"output_type":"stream","name":"stdout","text":["curren directory: /content\n","changed to: /content/drive/MyDrive/Colab Notebooks/AdversarialAI/Fixmatch\n"]}],"source":["import os \n","print(\"curren directory:\", os.getcwd())\n","\n","BASE_DIR = '/content/drive/MyDrive/Colab Notebooks/AdversarialAI/'\n","\n","FIXMATCH_DIR = BASE_DIR + \"Fixmatch/\"\n","os.chdir(FIXMATCH_DIR)\n","\n","print(\"changed to:\", os.getcwd())"]},{"cell_type":"markdown","metadata":{"id":"yupu6lLLTgdK"},"source":["# I. Training\n"]},{"cell_type":"markdown","metadata":{"id":"yRVSHXt-w6Vo"},"source":["## Train configurations"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":330,"status":"ok","timestamp":1682297824584,"user":{"displayName":"Hoang Ha Minh","userId":"09950483421498232129"},"user_tz":300},"id":"puIF-8UzJKs-"},"outputs":[],"source":["# Train configurations\n","dataset = 'cifar10'\n","subset_size = 30000\n","test_size = 5000\n","labeled_size = 400\n","poison_size = 300\n","seed = 56 # 92 previously\n","\n","exp_name = 'bird_frog'\n","poison_output = f\"./data/poison/{exp_name}\"\n","out = f'results/{dataset}@{exp_name}'\n","resume = out + '/checkpoint.pth.tar'\n","\n","batch_size = 32\n","max_epoch = 30\n","eval_steps = subset_size // batch_size + 1\n","total_steps = eval_steps * max_epoch\n","\n","\n","# targeted attack option\n","label_mali = 2 # airplane\n","label_source = 6 # deer"]},{"cell_type":"markdown","metadata":{"id":"AiKqal-JhXBP"},"source":["## Train unpoisoned model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2660,"status":"ok","timestamp":1681960084529,"user":{"displayName":"Hoang Ha Minh","userId":"09950483421498232129"},"user_tz":300},"id":"gRKZPK4FhasP","outputId":"1ad8b5a6-8c87-4148-ee8f-ec22b9228bc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n"]}],"source":["# Run training command\n","!python3 train.py --poison-size 0 --subset-size {subset_size} --test-size {test_size} --labeled-size {labeled_size} --out {out} --poison-output {poison_output} --total-steps {total_steps} --eval-step {eval_steps} --dataset cifar10 --arch wideresnet --batch-size {batch_size} --lr 0.03 --expand-labels --seed {seed} --dataset {dataset}"]},{"cell_type":"markdown","metadata":{"id":"5Gd1mQk1xAK3"},"source":["## From scratch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6jzq-J0YxDhD"},"outputs":[],"source":["# Run training command\n","!python3 train.py --subset-size {subset_size} --test-size {test_size} --labeled-size {labeled_size} --poison-size {poison_size} --out {out} --poison-output {poison_output} --total-steps {total_steps} --eval-step {eval_steps} --dataset cifar10 --arch wideresnet --batch-size {batch_size} --lr 0.03 --expand-labels --seed {seed} --dataset {dataset}"]},{"cell_type":"markdown","metadata":{"id":"TlG35ufZToua"},"source":["## Resume training"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8532549,"status":"ok","timestamp":1682293236579,"user":{"displayName":"Hoang Ha Minh","userId":"09950483421498232129"},"user_tz":300},"id":"_eMl4JhaxSaJ","outputId":"950dd74a-a316-4bf8-9088-2a2a23bd2235"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-23 21:18:28.419016: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-23 21:18:29.282508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","['/content/drive/MyDrive/Colab Notebooks/AdversarialAI/Fixmatch', '/content/drive/MyDrive/Colab Notebooks/AdversarialAI/Poisoner', '/env/python', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', './']\n","04/23/2023 21:18:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/23/2023 21:18:34 - INFO - __main__ -   {'gpu_id': 0, 'num_workers': 4, 'dataset': 'cifar10', 'expand_labels': True, 'arch': 'wideresnet', 'total_steps': 28140, 'eval_step': 938, 'start_epoch': 0, 'batch_size': 32, 'lr': 0.03, 'warmup': 0, 'wdecay': 0.0005, 'nesterov': True, 'use_ema': True, 'ema_decay': 0.999, 'mu': 7, 'lambda_u': 1, 'T': 1, 'threshold': 0.95, 'out': 'results/cifar10@bird_frog', 'resume': 'results/cifar10@bird_frog/checkpoint.pth.tar', 'seed': 5, 'amp': False, 'opt_level': 'O1', 'local_rank': -1, 'no_progress': False, 'num_labeled': 4000, 'subset_size': 30000, 'test_size': 5000, 'labeled_size': 400, 'poison_output': './data/poison/bird_frog', 'poison_size': 300, 'label_mali': -1, 'label_source': -1, 'world_size': 1, 'n_gpu': 1, 'device': device(type='cuda')}\n","Getting CIFAR10 data\n","getting cifar10 | subset size, labeled size, test size = [30000, 400, 5000]\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","labeled, unlabeled, test sizes: [400, 29600, 5000]\n","getting transform for cifar10\n","retrieved injected poison at ./data/poison/bird_frog/injected\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","added poison to the unlabeled dataset\n","04/23/2023 21:18:49 - INFO - models.wideresnet -   Model: WideResNet 28x2\n","04/23/2023 21:18:49 - INFO - __main__ -   Total params: 1.47M\n","04/23/2023 21:18:50 - INFO - __main__ -   ==> Resuming from checkpoint..\n","04/23/2023 21:18:54 - INFO - __main__ -   ***** Running training *****\n","04/23/2023 21:18:54 - INFO - __main__ -     Task = cifar10@4000\n","04/23/2023 21:18:54 - INFO - __main__ -     Num Epochs = 30\n","04/23/2023 21:18:54 - INFO - __main__ -     Batch size per GPU = 32\n","04/23/2023 21:18:54 - INFO - __main__ -     Total train batch size = 32\n","04/23/2023 21:18:54 - INFO - __main__ -     Total optimization steps = 28140\n","Train Epoch: 6/  30. Iter:  938/ 938. LR: 0.0289. Data: 0.072s. Batch: 0.357s. Loss: 0.4581. Loss_x: 0.1740. Loss_u: 0.2842. Mask: 0.47. : 100% 938/938 [05:34<00:00,  2.81it/s]\n","Test Iter:  157/ 157. Data: 0.006s. Batch: 0.017s. Loss: 1.3785. top1: 66.12. top5: 96.92. : 100% 157/157 [00:02<00:00, 58.41it/s]\n","04/23/2023 21:24:31 - INFO - __main__ -   top-1 acc: 66.12\n","04/23/2023 21:24:31 - INFO - __main__ -   top-5 acc: 96.92\n","04/23/2023 21:24:32 - INFO - __main__ -   Best top-1 acc: 66.12\n","04/23/2023 21:24:32 - INFO - __main__ -   Mean top-1 acc: 66.12\n","\n","Train Epoch: 7/  30. Iter:  938/ 938. LR: 0.0285. Data: 0.077s. Batch: 0.362s. Loss: 0.3326. Loss_x: 0.0299. Loss_u: 0.3027. Mask: 0.57. : 100% 938/938 [05:35<00:00,  2.79it/s]\n","Test Iter:  157/ 157. Data: 0.009s. Batch: 0.018s. Loss: 1.3587. top1: 68.68. top5: 97.00. : 100% 157/157 [00:02<00:00, 55.11it/s]\n","04/23/2023 21:30:10 - INFO - __main__ -   top-1 acc: 68.68\n","04/23/2023 21:30:10 - INFO - __main__ -   top-5 acc: 97.00\n","04/23/2023 21:30:11 - INFO - __main__ -   Best top-1 acc: 68.68\n","04/23/2023 21:30:11 - INFO - __main__ -   Mean top-1 acc: 67.40\n","\n","Train Epoch: 8/  30. Iter:  938/ 938. LR: 0.0280. Data: 0.074s. Batch: 0.358s. Loss: 0.3008. Loss_x: 0.0172. Loss_u: 0.2836. Mask: 0.60. : 100% 938/938 [05:33<00:00,  2.82it/s]\n","Test Iter:  157/ 157. Data: 0.011s. Batch: 0.022s. Loss: 1.2958. top1: 71.28. top5: 97.20. : 100% 157/157 [00:03<00:00, 44.68it/s]\n","04/23/2023 21:35:47 - INFO - __main__ -   top-1 acc: 71.28\n","04/23/2023 21:35:47 - INFO - __main__ -   top-5 acc: 97.20\n","04/23/2023 21:35:47 - INFO - __main__ -   Best top-1 acc: 71.28\n","04/23/2023 21:35:47 - INFO - __main__ -   Mean top-1 acc: 68.69\n","\n","Train Epoch: 9/  30. Iter:  938/ 938. LR: 0.0275. Data: 0.076s. Batch: 0.360s. Loss: 0.3068. Loss_x: 0.0242. Loss_u: 0.2826. Mask: 0.61. : 100% 938/938 [05:33<00:00,  2.81it/s]\n","Test Iter:  157/ 157. Data: 0.010s. Batch: 0.023s. Loss: 1.2626. top1: 73.06. top5: 97.28. : 100% 157/157 [00:03<00:00, 42.10it/s]\n","04/23/2023 21:41:25 - INFO - __main__ -   top-1 acc: 73.06\n","04/23/2023 21:41:25 - INFO - __main__ -   top-5 acc: 97.28\n","04/23/2023 21:41:25 - INFO - __main__ -   Best top-1 acc: 73.06\n","04/23/2023 21:41:25 - INFO - __main__ -   Mean top-1 acc: 69.78\n","\n","Train Epoch: 10/  30. Iter:  938/ 938. LR: 0.0269. Data: 0.082s. Batch: 0.367s. Loss: 0.2785. Loss_x: 0.0109. Loss_u: 0.2676. Mask: 0.63. : 100% 938/938 [05:39<00:00,  2.76it/s]\n","Test Iter:  157/ 157. Data: 0.007s. Batch: 0.017s. Loss: 1.2312. top1: 73.90. top5: 97.42. : 100% 157/157 [00:02<00:00, 57.72it/s]\n","04/23/2023 21:47:08 - INFO - __main__ -   top-1 acc: 73.90\n","04/23/2023 21:47:08 - INFO - __main__ -   top-5 acc: 97.42\n","04/23/2023 21:47:08 - INFO - __main__ -   Best top-1 acc: 73.90\n","04/23/2023 21:47:08 - INFO - __main__ -   Mean top-1 acc: 70.61\n","\n","Train Epoch: 11/  30. Iter:  938/ 938. LR: 0.0263. Data: 0.081s. Batch: 0.366s. Loss: 0.2827. Loss_x: 0.0169. Loss_u: 0.2658. Mask: 0.64. : 100% 938/938 [05:40<00:00,  2.76it/s]\n","Test Iter:  157/ 157. Data: 0.007s. Batch: 0.016s. Loss: 1.1749. top1: 75.22. top5: 97.58. : 100% 157/157 [00:02<00:00, 62.27it/s]\n","04/23/2023 21:52:51 - INFO - __main__ -   top-1 acc: 75.22\n","04/23/2023 21:52:51 - INFO - __main__ -   top-5 acc: 97.58\n","04/23/2023 21:52:51 - INFO - __main__ -   Best top-1 acc: 75.22\n","04/23/2023 21:52:51 - INFO - __main__ -   Mean top-1 acc: 71.38\n","\n","Train Epoch: 12/  30. Iter:  938/ 938. LR: 0.0256. Data: 0.076s. Batch: 0.360s. Loss: 0.2589. Loss_x: 0.0078. Loss_u: 0.2512. Mask: 0.66. : 100% 938/938 [05:34<00:00,  2.80it/s]\n","Test Iter:  157/ 157. Data: 0.006s. Batch: 0.014s. Loss: 1.1406. top1: 76.46. top5: 97.88. : 100% 157/157 [00:02<00:00, 70.11it/s]\n","04/23/2023 21:58:28 - INFO - __main__ -   top-1 acc: 76.46\n","04/23/2023 21:58:28 - INFO - __main__ -   top-5 acc: 97.88\n","04/23/2023 21:58:28 - INFO - __main__ -   Best top-1 acc: 76.46\n","04/23/2023 21:58:28 - INFO - __main__ -   Mean top-1 acc: 72.10\n","\n","Train Epoch: 13/  30. Iter:  938/ 938. LR: 0.0248. Data: 0.075s. Batch: 0.359s. Loss: 0.2639. Loss_x: 0.0119. Loss_u: 0.2520. Mask: 0.67. : 100% 938/938 [05:34<00:00,  2.81it/s]\n","Test Iter:  157/ 157. Data: 0.010s. Batch: 0.020s. Loss: 1.0985. top1: 77.14. top5: 98.04. : 100% 157/157 [00:03<00:00, 48.65it/s]\n","04/23/2023 22:04:05 - INFO - __main__ -   top-1 acc: 77.14\n","04/23/2023 22:04:05 - INFO - __main__ -   top-5 acc: 98.04\n","04/23/2023 22:04:06 - INFO - __main__ -   Best top-1 acc: 77.14\n","04/23/2023 22:04:06 - INFO - __main__ -   Mean top-1 acc: 72.73\n","\n","Train Epoch: 14/  30. Iter:  938/ 938. LR: 0.0240. Data: 0.079s. Batch: 0.365s. Loss: 0.2589. Loss_x: 0.0079. Loss_u: 0.2509. Mask: 0.68. : 100% 938/938 [05:39<00:00,  2.77it/s]\n","Test Iter:  157/ 157. Data: 0.008s. Batch: 0.016s. Loss: 1.0369. top1: 78.54. top5: 98.10. : 100% 157/157 [00:02<00:00, 60.21it/s]\n","04/23/2023 22:09:47 - INFO - __main__ -   top-1 acc: 78.54\n","04/23/2023 22:09:47 - INFO - __main__ -   top-5 acc: 98.10\n","04/23/2023 22:09:47 - INFO - __main__ -   Best top-1 acc: 78.54\n","04/23/2023 22:09:47 - INFO - __main__ -   Mean top-1 acc: 73.38\n","\n","Train Epoch: 15/  30. Iter:  938/ 938. LR: 0.0232. Data: 0.077s. Batch: 0.362s. Loss: 0.2576. Loss_x: 0.0104. Loss_u: 0.2472. Mask: 0.69. : 100% 938/938 [05:36<00:00,  2.79it/s]\n","Test Iter:  157/ 157. Data: 0.009s. Batch: 0.019s. Loss: 1.0052. top1: 79.50. top5: 98.10. : 100% 157/157 [00:03<00:00, 52.33it/s]\n","04/23/2023 22:15:27 - INFO - __main__ -   top-1 acc: 79.50\n","04/23/2023 22:15:27 - INFO - __main__ -   top-5 acc: 98.10\n","04/23/2023 22:15:27 - INFO - __main__ -   Best top-1 acc: 79.50\n","04/23/2023 22:15:27 - INFO - __main__ -   Mean top-1 acc: 73.99\n","\n","Train Epoch: 16/  30. Iter:  938/ 938. LR: 0.0223. Data: 0.077s. Batch: 0.362s. Loss: 0.2468. Loss_x: 0.0055. Loss_u: 0.2412. Mask: 0.71. : 100% 938/938 [05:36<00:00,  2.79it/s]\n","Test Iter:  157/ 157. Data: 0.011s. Batch: 0.024s. Loss: 0.9721. top1: 80.10. top5: 98.34. : 100% 157/157 [00:03<00:00, 40.55it/s]\n","04/23/2023 22:21:07 - INFO - __main__ -   top-1 acc: 80.10\n","04/23/2023 22:21:07 - INFO - __main__ -   top-5 acc: 98.34\n","04/23/2023 22:21:07 - INFO - __main__ -   Best top-1 acc: 80.10\n","04/23/2023 22:21:07 - INFO - __main__ -   Mean top-1 acc: 74.55\n","\n","Train Epoch: 17/  30. Iter:  938/ 938. LR: 0.0214. Data: 0.078s. Batch: 0.364s. Loss: 0.2456. Loss_x: 0.0074. Loss_u: 0.2382. Mask: 0.71. : 100% 938/938 [05:37<00:00,  2.78it/s]\n","Test Iter:  157/ 157. Data: 0.013s. Batch: 0.025s. Loss: 0.9272. top1: 80.82. top5: 98.50. : 100% 157/157 [00:04<00:00, 39.18it/s]\n","04/23/2023 22:26:49 - INFO - __main__ -   top-1 acc: 80.82\n","04/23/2023 22:26:49 - INFO - __main__ -   top-5 acc: 98.50\n","04/23/2023 22:26:49 - INFO - __main__ -   Best top-1 acc: 80.82\n","04/23/2023 22:26:49 - INFO - __main__ -   Mean top-1 acc: 75.07\n","\n","Train Epoch: 18/  30. Iter:  938/ 938. LR: 0.0204. Data: 0.077s. Batch: 0.362s. Loss: 0.2473. Loss_x: 0.0067. Loss_u: 0.2406. Mask: 0.72. : 100% 938/938 [05:35<00:00,  2.79it/s]\n","Test Iter:  157/ 157. Data: 0.013s. Batch: 0.024s. Loss: 0.8938. top1: 81.34. top5: 98.50. : 100% 157/157 [00:03<00:00, 41.61it/s]\n","04/23/2023 22:32:28 - INFO - __main__ -   top-1 acc: 81.34\n","04/23/2023 22:32:28 - INFO - __main__ -   top-5 acc: 98.50\n","04/23/2023 22:32:29 - INFO - __main__ -   Best top-1 acc: 81.34\n","04/23/2023 22:32:29 - INFO - __main__ -   Mean top-1 acc: 75.55\n","\n","Train Epoch: 19/  30. Iter:  938/ 938. LR: 0.0193. Data: 0.078s. Batch: 0.364s. Loss: 0.2395. Loss_x: 0.0061. Loss_u: 0.2334. Mask: 0.73. : 100% 938/938 [05:37<00:00,  2.78it/s]\n","Test Iter:  157/ 157. Data: 0.014s. Batch: 0.027s. Loss: 0.8692. top1: 81.86. top5: 98.62. : 100% 157/157 [00:04<00:00, 37.09it/s]\n","04/23/2023 22:38:10 - INFO - __main__ -   top-1 acc: 81.86\n","04/23/2023 22:38:10 - INFO - __main__ -   top-5 acc: 98.62\n","04/23/2023 22:38:11 - INFO - __main__ -   Best top-1 acc: 81.86\n","04/23/2023 22:38:11 - INFO - __main__ -   Mean top-1 acc: 76.00\n","\n","Train Epoch: 20/  30. Iter:  938/ 938. LR: 0.0183. Data: 0.083s. Batch: 0.369s. Loss: 0.2297. Loss_x: 0.0035. Loss_u: 0.2262. Mask: 0.74. : 100% 938/938 [05:41<00:00,  2.75it/s]\n","Test Iter:  157/ 157. Data: 0.007s. Batch: 0.016s. Loss: 0.8430. top1: 82.58. top5: 98.64. : 100% 157/157 [00:02<00:00, 60.34it/s]\n","04/23/2023 22:43:55 - INFO - __main__ -   top-1 acc: 82.58\n","04/23/2023 22:43:55 - INFO - __main__ -   top-5 acc: 98.64\n","04/23/2023 22:43:55 - INFO - __main__ -   Best top-1 acc: 82.58\n","04/23/2023 22:43:55 - INFO - __main__ -   Mean top-1 acc: 76.44\n","\n","Train Epoch: 21/  30. Iter:  938/ 938. LR: 0.0172. Data: 0.077s. Batch: 0.361s. Loss: 0.2327. Loss_x: 0.0053. Loss_u: 0.2274. Mask: 0.74. : 100% 938/938 [05:35<00:00,  2.79it/s]\n","Test Iter:  157/ 157. Data: 0.009s. Batch: 0.018s. Loss: 0.8113. top1: 82.92. top5: 98.76. : 100% 157/157 [00:02<00:00, 53.48it/s]\n","04/23/2023 22:49:34 - INFO - __main__ -   top-1 acc: 82.92\n","04/23/2023 22:49:34 - INFO - __main__ -   top-5 acc: 98.76\n","04/23/2023 22:49:34 - INFO - __main__ -   Best top-1 acc: 82.92\n","04/23/2023 22:49:34 - INFO - __main__ -   Mean top-1 acc: 76.84\n","\n","Train Epoch: 22/  30. Iter:  938/ 938. LR: 0.0160. Data: 0.077s. Batch: 0.359s. Loss: 0.2282. Loss_x: 0.0037. Loss_u: 0.2244. Mask: 0.76. : 100% 938/938 [05:33<00:00,  2.81it/s]\n","Test Iter:  157/ 157. Data: 0.013s. Batch: 0.027s. Loss: 0.7894. top1: 83.70. top5: 98.84. : 100% 157/157 [00:04<00:00, 36.84it/s]\n","04/23/2023 22:55:12 - INFO - __main__ -   top-1 acc: 83.70\n","04/23/2023 22:55:12 - INFO - __main__ -   top-5 acc: 98.84\n","04/23/2023 22:55:12 - INFO - __main__ -   Best top-1 acc: 83.70\n","04/23/2023 22:55:12 - INFO - __main__ -   Mean top-1 acc: 77.25\n","\n","Train Epoch: 23/  30. Iter:  938/ 938. LR: 0.0148. Data: 0.077s. Batch: 0.361s. Loss: 0.2230. Loss_x: 0.0026. Loss_u: 0.2205. Mask: 0.77. : 100% 938/938 [05:34<00:00,  2.81it/s]\n","Test Iter:  157/ 157. Data: 0.005s. Batch: 0.013s. Loss: 0.7641. top1: 84.18. top5: 98.80. : 100% 157/157 [00:02<00:00, 74.47it/s]\n","04/23/2023 23:00:49 - INFO - __main__ -   top-1 acc: 84.18\n","04/23/2023 23:00:49 - INFO - __main__ -   top-5 acc: 98.80\n","04/23/2023 23:00:49 - INFO - __main__ -   Best top-1 acc: 84.18\n","04/23/2023 23:00:49 - INFO - __main__ -   Mean top-1 acc: 77.63\n","\n","Train Epoch: 24/  30. Iter:  938/ 938. LR: 0.0136. Data: 0.076s. Batch: 0.362s. Loss: 0.2185. Loss_x: 0.0029. Loss_u: 0.2157. Mask: 0.77. : 100% 938/938 [05:37<00:00,  2.78it/s]\n","Test Iter:  157/ 157. Data: 0.006s. Batch: 0.013s. Loss: 0.7430. top1: 84.42. top5: 98.88. : 100% 157/157 [00:02<00:00, 74.98it/s]\n","04/23/2023 23:06:28 - INFO - __main__ -   top-1 acc: 84.42\n","04/23/2023 23:06:28 - INFO - __main__ -   top-5 acc: 98.88\n","04/23/2023 23:06:28 - INFO - __main__ -   Best top-1 acc: 84.42\n","04/23/2023 23:06:28 - INFO - __main__ -   Mean top-1 acc: 77.99\n","\n","Train Epoch: 25/  30. Iter:  938/ 938. LR: 0.0124. Data: 0.077s. Batch: 0.362s. Loss: 0.2171. Loss_x: 0.0022. Loss_u: 0.2149. Mask: 0.78. : 100% 938/938 [05:37<00:00,  2.78it/s]\n","Test Iter:  157/ 157. Data: 0.008s. Batch: 0.019s. Loss: 0.7184. top1: 85.16. top5: 98.72. : 100% 157/157 [00:02<00:00, 52.99it/s]\n","04/23/2023 23:12:09 - INFO - __main__ -   top-1 acc: 85.16\n","04/23/2023 23:12:09 - INFO - __main__ -   top-5 acc: 98.72\n","04/23/2023 23:12:09 - INFO - __main__ -   Best top-1 acc: 85.16\n","04/23/2023 23:12:09 - INFO - __main__ -   Mean top-1 acc: 78.35\n","\n","Train Epoch: 26/  30. Iter:  938/ 938. LR: 0.0111. Data: 0.077s. Batch: 0.362s. Loss: 0.2122. Loss_x: 0.0019. Loss_u: 0.2103. Mask: 0.79. : 100% 938/938 [05:36<00:00,  2.79it/s]\n","Test Iter:  157/ 157. Data: 0.007s. Batch: 0.015s. Loss: 0.6940. top1: 85.46. top5: 98.94. : 100% 157/157 [00:02<00:00, 66.83it/s]\n","04/23/2023 23:17:47 - INFO - __main__ -   top-1 acc: 85.46\n","04/23/2023 23:17:47 - INFO - __main__ -   top-5 acc: 98.94\n","04/23/2023 23:17:47 - INFO - __main__ -   Best top-1 acc: 85.46\n","04/23/2023 23:17:47 - INFO - __main__ -   Mean top-1 acc: 79.32\n","\n","Train Epoch: 27/  30. Iter:  938/ 938. LR: 0.0098. Data: 0.077s. Batch: 0.362s. Loss: 0.2068. Loss_x: 0.0016. Loss_u: 0.2053. Mask: 0.80. : 100% 938/938 [05:37<00:00,  2.78it/s]\n","Test Iter:  157/ 157. Data: 0.008s. Batch: 0.017s. Loss: 0.6766. top1: 85.86. top5: 99.00. : 100% 157/157 [00:02<00:00, 57.43it/s]\n","04/23/2023 23:23:27 - INFO - __main__ -   top-1 acc: 85.86\n","04/23/2023 23:23:27 - INFO - __main__ -   top-5 acc: 99.00\n","04/23/2023 23:23:28 - INFO - __main__ -   Best top-1 acc: 85.86\n","04/23/2023 23:23:28 - INFO - __main__ -   Mean top-1 acc: 80.17\n","\n","Train Epoch: 28/  30. Iter:  938/ 938. LR: 0.0085. Data: 0.075s. Batch: 0.360s. Loss: 0.2054. Loss_x: 0.0015. Loss_u: 0.2039. Mask: 0.81. : 100% 938/938 [05:34<00:00,  2.80it/s]\n","Test Iter:  157/ 157. Data: 0.009s. Batch: 0.020s. Loss: 0.6608. top1: 86.30. top5: 98.98. : 100% 157/157 [00:03<00:00, 49.12it/s]\n","04/23/2023 23:29:06 - INFO - __main__ -   top-1 acc: 86.30\n","04/23/2023 23:29:06 - INFO - __main__ -   top-5 acc: 98.98\n","04/23/2023 23:29:06 - INFO - __main__ -   Best top-1 acc: 86.30\n","04/23/2023 23:29:06 - INFO - __main__ -   Mean top-1 acc: 80.93\n","\n","Train Epoch: 29/  30. Iter:  938/ 938. LR: 0.0072. Data: 0.080s. Batch: 0.365s. Loss: 0.1994. Loss_x: 0.0011. Loss_u: 0.1983. Mask: 0.82. : 100% 938/938 [05:38<00:00,  2.77it/s]\n","Test Iter:  157/ 157. Data: 0.008s. Batch: 0.017s. Loss: 0.6421. top1: 86.66. top5: 99.02. : 100% 157/157 [00:02<00:00, 58.15it/s]\n","04/23/2023 23:34:47 - INFO - __main__ -   top-1 acc: 86.66\n","04/23/2023 23:34:47 - INFO - __main__ -   top-5 acc: 99.02\n","04/23/2023 23:34:47 - INFO - __main__ -   Best top-1 acc: 86.66\n","04/23/2023 23:34:47 - INFO - __main__ -   Mean top-1 acc: 81.61\n","\n","Train Epoch: 30/  30. Iter:  938/ 938. LR: 0.0059. Data: 0.083s. Batch: 0.369s. Loss: 0.1936. Loss_x: 0.0010. Loss_u: 0.1926. Mask: 0.83. : 100% 938/938 [05:43<00:00,  2.73it/s]\n","Test Iter:  157/ 157. Data: 0.006s. Batch: 0.014s. Loss: 0.6261. top1: 86.86. top5: 99.12. : 100% 157/157 [00:02<00:00, 68.14it/s]\n","04/23/2023 23:40:33 - INFO - __main__ -   top-1 acc: 86.86\n","04/23/2023 23:40:33 - INFO - __main__ -   top-5 acc: 99.12\n","04/23/2023 23:40:33 - INFO - __main__ -   Best top-1 acc: 86.86\n","04/23/2023 23:40:33 - INFO - __main__ -   Mean top-1 acc: 82.25\n","\n"]}],"source":["# Run training command\n","!python3 train.py --resume {resume} --subset-size {subset_size} --test-size {test_size} --labeled-size {labeled_size} --poison-size {poison_size} --out {out} --poison-output {poison_output} --total-steps {total_steps} --eval-step {eval_steps} --dataset cifar10 --arch wideresnet --batch-size {batch_size} --lr 0.03 --expand-labels --seed 5 --dataset {dataset}"]},{"cell_type":"markdown","metadata":{"id":"7syihkqVVa8K"},"source":["## Targeted attack training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"paWWNm9DVW_2","outputId":"99baa775-d496-4373-80b2-69134d9668db"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-04-23 20:29:12.496613: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-23 20:29:13.367383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","['/content/drive/MyDrive/Colab Notebooks/AdversarialAI/Fixmatch', '/content/drive/MyDrive/Colab Notebooks/AdversarialAI/Poisoner', '/env/python', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', './']\n","04/23/2023 20:29:15 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","04/23/2023 20:29:15 - INFO - __main__ -   {'gpu_id': 0, 'num_workers': 4, 'dataset': 'cifar10', 'expand_labels': True, 'arch': 'wideresnet', 'total_steps': 28140, 'eval_step': 938, 'start_epoch': 0, 'batch_size': 32, 'lr': 0.03, 'warmup': 0, 'wdecay': 0.0005, 'nesterov': True, 'use_ema': True, 'ema_decay': 0.999, 'mu': 7, 'lambda_u': 1, 'T': 1, 'threshold': 0.95, 'out': 'results/cifar10@bird_frog', 'resume': '', 'seed': 56, 'amp': False, 'opt_level': 'O1', 'local_rank': -1, 'no_progress': False, 'num_labeled': 4000, 'subset_size': 30000, 'test_size': 5000, 'labeled_size': 400, 'poison_output': './data/poison/bird_frog', 'poison_size': 300, 'label_mali': 2, 'label_source': 6, 'world_size': 1, 'n_gpu': 1, 'device': device(type='cuda')}\n","Getting CIFAR10 data\n","getting cifar10 | subset size, labeled size, test size = [30000, 400, 5000]\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","labeled, unlabeled, test sizes: [400, 29600, 5000]\n","getting transform for cifar10\n","malicious: bird , target: frog\n","x_star: <class 'numpy.ndarray'>\n","x_target: <class 'numpy.ndarray'>\n","target and malicious images saved to ./data/poison/bird_frog\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","added poison to the unlabeled dataset\n","04/23/2023 20:29:27 - INFO - models.wideresnet -   Model: WideResNet 28x2\n","04/23/2023 20:29:27 - INFO - __main__ -   Total params: 1.47M\n","04/23/2023 20:29:28 - INFO - __main__ -   ***** Running training *****\n","04/23/2023 20:29:28 - INFO - __main__ -     Task = cifar10@4000\n","04/23/2023 20:29:28 - INFO - __main__ -     Num Epochs = 30\n","04/23/2023 20:29:28 - INFO - __main__ -     Batch size per GPU = 32\n","04/23/2023 20:29:28 - INFO - __main__ -     Total train batch size = 32\n","04/23/2023 20:29:28 - INFO - __main__ -     Total optimization steps = 28140\n","Train Epoch: 1/  30. Iter:  938/ 938. LR: 0.0300. Data: 0.073s. Batch: 0.359s. Loss: 0.8586. Loss_x: 0.7135. Loss_u: 0.1451. Mask: 0.16. : 100% 938/938 [05:36<00:00,  2.79it/s]\n","Test Iter:  157/ 157. Data: 0.008s. Batch: 0.021s. Loss: 1.9052. top1: 29.92. top5: 83.48. : 100% 157/157 [00:03<00:00, 47.52it/s]\n","04/23/2023 20:35:07 - INFO - __main__ -   top-1 acc: 29.92\n","04/23/2023 20:35:07 - INFO - __main__ -   top-5 acc: 83.48\n","04/23/2023 20:35:08 - INFO - __main__ -   Best top-1 acc: 29.92\n","04/23/2023 20:35:08 - INFO - __main__ -   Mean top-1 acc: 29.92\n","\n","Train Epoch: 2/  30. Iter:  938/ 938. LR: 0.0299. Data: 0.077s. Batch: 0.362s. Loss: 0.4280. Loss_x: 0.0902. Loss_u: 0.3379. Mask: 0.40. : 100% 938/938 [05:35<00:00,  2.79it/s]\n","Test Iter:  157/ 157. Data: 0.013s. Batch: 0.025s. Loss: 1.9320. top1: 44.24. top5: 91.70. : 100% 157/157 [00:03<00:00, 39.66it/s]\n","04/23/2023 20:40:47 - INFO - __main__ -   top-1 acc: 44.24\n","04/23/2023 20:40:47 - INFO - __main__ -   top-5 acc: 91.70\n","04/23/2023 20:40:48 - INFO - __main__ -   Best top-1 acc: 44.24\n","04/23/2023 20:40:48 - INFO - __main__ -   Mean top-1 acc: 37.08\n","\n","Train Epoch: 3/  30. Iter:  938/ 938. LR: 0.0297. Data: 0.077s. Batch: 0.360s. Loss: 0.3819. Loss_x: 0.0432. Loss_u: 0.3387. Mask: 0.47. : 100% 938/938 [05:33<00:00,  2.81it/s]\n","Test Iter:  157/ 157. Data: 0.006s. Batch: 0.014s. Loss: 1.9480. top1: 52.96. top5: 93.62. : 100% 157/157 [00:02<00:00, 67.65it/s]\n","04/23/2023 20:46:24 - INFO - __main__ -   top-1 acc: 52.96\n","04/23/2023 20:46:24 - INFO - __main__ -   top-5 acc: 93.62\n","04/23/2023 20:46:24 - INFO - __main__ -   Best top-1 acc: 52.96\n","04/23/2023 20:46:24 - INFO - __main__ -   Mean top-1 acc: 42.37\n","\n","Train Epoch: 4/  30. Iter:  938/ 938. LR: 0.0295. Data: 0.076s. Batch: 0.359s. Loss: 0.3593. Loss_x: 0.0416. Loss_u: 0.3177. Mask: 0.49. : 100% 938/938 [05:34<00:00,  2.80it/s]\n","Test Iter:  157/ 157. Data: 0.007s. Batch: 0.015s. Loss: 1.8915. top1: 57.44. top5: 94.42. : 100% 157/157 [00:02<00:00, 65.61it/s]\n","04/23/2023 20:52:01 - INFO - __main__ -   top-1 acc: 57.44\n","04/23/2023 20:52:01 - INFO - __main__ -   top-5 acc: 94.42\n","04/23/2023 20:52:01 - INFO - __main__ -   Best top-1 acc: 57.44\n","04/23/2023 20:52:01 - INFO - __main__ -   Mean top-1 acc: 46.14\n","\n","Train Epoch: 5/  30. Iter:  938/ 938. LR: 0.0292. Data: 0.078s. Batch: 0.362s. Loss: 0.3265. Loss_x: 0.0249. Loss_u: 0.3016. Mask: 0.53. : 100% 938/938 [05:37<00:00,  2.78it/s]\n","Test Iter:  157/ 157. Data: 0.006s. Batch: 0.015s. Loss: 1.8179. top1: 60.84. top5: 95.00. : 100% 157/157 [00:02<00:00, 67.68it/s]\n","04/23/2023 20:57:40 - INFO - __main__ -   top-1 acc: 60.84\n","04/23/2023 20:57:40 - INFO - __main__ -   top-5 acc: 95.00\n","04/23/2023 20:57:41 - INFO - __main__ -   Best top-1 acc: 60.84\n","04/23/2023 20:57:41 - INFO - __main__ -   Mean top-1 acc: 49.08\n","\n","Train Epoch: 6/  30. Iter:  689/ 938. LR: 0.0290. Data: 0.082s. Batch: 0.366s. Loss: 0.3324. Loss_x: 0.0395. Loss_u: 0.2929. Mask: 0.53. :  73% 689/938 [04:09<01:26,  2.88it/s]"]}],"source":["# Run training command\n","!python3 train.py --label-mali {label_mali} --label-source {label_source} --subset-size {subset_size} --test-size {test_size} --labeled-size {labeled_size} --poison-size {poison_size} --out {out} --poison-output {poison_output} --total-steps {total_steps} --eval-step {eval_steps} --dataset cifar10 --arch wideresnet --batch-size {batch_size} --lr 0.03 --expand-labels --seed {seed} --dataset {dataset} "]},{"cell_type":"markdown","metadata":{"id":"-DJxrrgOJL05"},"source":["# III. Test"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22519,"status":"ok","timestamp":1682297856394,"user":{"displayName":"Hoang Ha Minh","userId":"09950483421498232129"},"user_tz":300},"id":"MfEGTMIG14Qd","outputId":"7b3e0c18-251d-4cc9-b625-8d7192012dd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["['/content', '/content/drive/MyDrive/Colab Notebooks/AdversarialAI/Poisoner', '/env/python', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.9/dist-packages/IPython/extensions', '/root/.ipython', './']\n","Using cuda\n","Loaded model at results/cifar10@bird_frog/model_best.pth.tar\n","getting transform for cifar10\n"]}],"source":["import torch\n","from torch.utils.data import DataLoader, SequentialSampler\n","import torch.nn.functional as F\n","from utils import AverageMeter, accuracy\n","from tqdm import tqdm\n","import models.wideresnet as models\n","import time\n","import logging\n","\n","import sys\n","sys.path.insert(1, BASE_DIR + 'Poisoner')\n","from Poisoner import Poisoner\n","from get_datasets import get_subset_cifar10\n","from CustomTransforms import get_fixmatch_transforms\n","\n","# logger\n","logger = logging.getLogger(__name__)\n","logging.basicConfig(\n","    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","    datefmt=\"%m/%d/%Y %H:%M:%S\",\n","    level=logging.INFO)\n","\n","# prepare cuda\n","if torch.cuda.is_available():\n","  device = \"cuda\"\n","else:\n","  device = \"cpu\"\n","print(f\"Using {device}\")\n","\n","# load model\n","model = models.build_wideresnet(depth=28,\n","                            widen_factor=2,\n","                            dropout=0,\n","                            num_classes=10)\n","model.to(device)\n","CHECKPOINT_PATH = \"{}/model_best.pth.tar\".format(out) \n","# CHECKPOINT_PATH = \"results/cifar10@poisoned50k.100/model_best.pth.tar\"\n","checkpoint = torch.load(CHECKPOINT_PATH)\n","model.load_state_dict(checkpoint['state_dict'])\n","model.eval()\n","print(\"Loaded model at\", CHECKPOINT_PATH)\n","\n","# load transforms\n","transform_labeled, transform_unlabeled, transform_test = get_fixmatch_transforms(dataset=dataset)"]},{"cell_type":"markdown","metadata":{"id":"2yrbgXw2J7f7"},"source":["## Test model on entire test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNp2ve02J-4D"},"outputs":[],"source":["def test_on_testset(test_loader, model, device):\n","    logger = logging.getLogger(__name__)\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","    end = time.time()\n","\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(test_loader):\n","            data_time.update(time.time() - end)\n","            model.eval()\n","\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","            outputs = model(inputs)\n","            loss = F.cross_entropy(outputs, targets)\n","\n","            prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))\n","            losses.update(loss.item(), inputs.shape[0])\n","            top1.update(prec1.item(), inputs.shape[0])\n","            top5.update(prec5.item(), inputs.shape[0])\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","    logger.info(\"top-1 acc: {:.2f}\".format(top1.avg))\n","    logger.info(\"top-5 acc: {:.2f}\".format(top5.avg))\n","    return losses.avg, top1.avg\n","\n","\n","# load test data\n","labeled_dataset, unlabeled_dataset, test_dataset = get_subset_cifar10()\n","test_dataset.transform = transform_test\n","test_dataset.asPIL = True\n","\n","test_loader = DataLoader(test_dataset,\n","                        sampler=SequentialSampler(test_dataset),\n","                        batch_size=8,\n","                        num_workers=1)\n","\n","# test\n","test_on_testset(test_loader, model, device)"]},{"cell_type":"markdown","metadata":{"id":"9pCOgtiJLRGy"},"source":["## Test attack success"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1199,"status":"ok","timestamp":1682297917958,"user":{"displayName":"Hoang Ha Minh","userId":"09950483421498232129"},"user_tz":300},"id":"pg3lcnZ9LSyz","outputId":"6f8b0676-e53a-4cc7-d7a8-7e013c9d92e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3.1292e-10, 1.1148e-09, 2.8888e-06, 6.6485e-07, 9.9999e-01, 6.6108e-08,\n","         1.9455e-06, 1.6962e-06, 2.9600e-09, 1.0438e-08]], device='cuda:0',\n","       grad_fn=<SoftmaxBackward0>)\n","prediction: deer\n"]}],"source":["from PIL import Image\n","import numpy as np\n","\n","CHOSEN_POISON_PATH = f'{exp_name}/source_frog.jpg'\n","# CHOSEN_POISON_PATH = f'{exp_name}/injected/injected_0.001.jpg' # last 0.705, 0.683\n","label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","# label_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n","# label_names = range(10)\n","\n","with Image.open(FIXMATCH_DIR + 'data/poison/' + CHOSEN_POISON_PATH) as im:\n","    transformed_im = transform_test(im).to(device)\n","    inputs = torch.unsqueeze(transformed_im, dim=0)\n","    model.eval()\n","    outputs = model(inputs)\n","    outputs = torch.softmax(outputs, dim=1)\n","    print(outputs)\n","    label_idx = torch.argmax(outputs).cpu().numpy()\n","    label = label_names[label_idx]\n","    print(\"prediction:\", label)\n","\n","\n","# march5night --> Fail 50k.10\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nm0-ytsY6FPJ"},"outputs":[],"source":["labeled_dataset, unlabeled_dataset, test_dataset = get_subset_cifar10()\n","test_dataset.transform = transform_test\n","test_dataset.asPIL = True\n","\n","test_loader = DataLoader(test_dataset,\n","                        sampler=SequentialSampler(test_dataset),\n","                        batch_size=8,\n","                        num_workers=1)\n","\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npZ04mc5d7_M"},"outputs":[],"source":["counts = [0]*10\n","for imgs, labels in test_loader:\n","    inputs = imgs.to(device)\n","    outputs = model(inputs)\n","    outputs = torch.softmax(outputs, dim=1)\n","    label_indices = torch.argmax(outputs, dim=1).cpu().numpy()\n","    for idx in label_indices:\n","        counts[idx] += 1\n","print(counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTnrZPF0eD2_"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}